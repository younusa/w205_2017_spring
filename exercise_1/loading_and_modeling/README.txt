Loading and Modeling

In order to succesfully run load_data_lakes.sh for exercise 1, first run a UCB AMI instance. Second, run the start_hadoop.sh that should be under the root user. At this point, switch to the w205 user, clone git repository in shell command window and run the load_data_lakes.sh script that is embedded im the loading_and_modeling folder. This script will download and rename the relevant csv data needed to complete exercise 1 
